{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FbWoGOis4KoG"
   },
   "source": [
    "# L3: Multi-agent Customer Support Automation (with Hugging Face)\n",
    "\n",
    "This notebook runs the same customer support automation system, but has been modified to use a free, powerful LLM from Hugging Face instead of OpenAI."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Your To-Do:\n",
    "1. In Google Colab, click on the key icon on the left sidebar (`Secrets`).\n",
    "2. Create a new secret named `HF_TOKEN`.\n",
    "3. Paste your Hugging Face API token into the value field.\n",
    "4. Enable the toggle to make this secret available to the notebook.\n",
    "5. Run the cells below!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to install the necessary libraries. We've added `langchain-huggingface` to connect to our new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install crewai==0.28.8 crewai_tools==0.1.6 langchain_community==0.0.29 langchain-huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_LQ5_lop4KJq"
   },
   "outputs": [],
   "source": [
    "# Warning control\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries and Set Up the Free LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from google.colab import userdata\n",
    "from crewai import Agent, Task, Crew\n",
    "from langchain_huggingface import HuggingFaceHub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up the Hugging Face API token from Colab Secrets\n",
    "os.environ[\"HUGGINGFACE_API_TOKEN\"] = userdata.get('HF_TOKEN')\n",
    "\n",
    "# Instantiate the free LLM from Hugging Face\n",
    "# Mixtral-8x7B is a powerful and popular open-source model\n",
    "huggingface_llm = HuggingFaceHub(\n",
    "    repo_id=\"mistralai/Mixtral-8x7B-Instruct-v0.1\", \n",
    "    model_kwargs={\"temperature\": 0.7, \"max_new_tokens\": 1500}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Role Playing, Focus and Cooperation\n",
    "\n",
    "Now we define our agents. Notice the new `llm=huggingface_llm` parameter. This is where we tell each agent to use our free model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "support_agent = Agent(\n",
    "    role=\"Senior Support Representative\",\n",
    "\tgoal=\"Be the most friendly and helpful \"\n",
    "        \"support representative in your team\",\n",
    "\tbackstory=(\n",
    "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
    "        \" are now working on providing \"\n",
    "\t\t\"support to {customer}, a super important customer \"\n",
    "        \" for your company.\"\n",
    "\t\t\"You need to make sure that you provide the best support!\"\n",
    "\t\t\"Make sure to provide full complete answers, \"\n",
    "        \" and make no assumptions.\"\n",
    "\t),\n",
    "\tallow_delegation=False,\n",
    "\tverbose=True,\n",
    "    llm=huggingface_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 285
   },
   "outputs": [],
   "source": [
    "support_quality_assurance_agent = Agent(\n",
    "\trole=\"Support Quality Assurance Specialist\",\n",
    "\tgoal=\"Get recognition for providing the \"\n",
    "    \"best support quality assurance in your team\",\n",
    "\tbackstory=(\n",
    "\t\t\"You work at crewAI (https://crewai.com) and \"\n",
    "        \"are now working with your team \"\n",
    "\t\t\"on a request from {customer} ensuring that \"\n",
    "        \"the support representative is \"\n",
    "\t\t\"providing the best support possible.\\n\"\n",
    "\t\t\"You need to make sure that the support representative \"\n",
    "        \"is providing full\"\n",
    "\t\t\"complete answers, and make no assumptions.\"\n",
    "\t),\n",
    "\tverbose=True,\n",
    "    llm=huggingface_llm\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tools, Guardrails and Memory\n",
    "\n",
    "The rest of the workflow is exactly the same. The agents will use the tools and follow the tasks as defined, but all their reasoning will be powered by the Hugging Face model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "from crewai_tools import SerperDevTool, \\\n",
    "                         ScrapeWebsiteTool, \\\n",
    "                         WebsiteSearchTool"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Instantiate a document scraper tool.\n",
    "- The tool will scrape a page (only 1 URL) of the CrewAI documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "docs_scrape_tool = ScrapeWebsiteTool(\n",
    "    website_url=\"https://docs.crewai.com/how-to/Creating-a-Crew-and-kick-it-off/\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating Tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 421
   },
   "outputs": [],
   "source": [
    "inquiry_resolution = Task(\n",
    "    description=(\n",
    "        \"{customer} just reached out with a super important ask:\\n\"\n",
    "\t    \"{inquiry}\\n\\n\"\n",
    "        \"{person} from {customer} is the one that reached out. \"\n",
    "\t\t\"Make sure to use everything you know \"\n",
    "        \"to provide the best support possible.\"\n",
    "\t\t\"You must strive to provide a complete \"\n",
    "        \"and accurate response to the customer's inquiry.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "\t    \"A detailed, informative response to the \"\n",
    "        \"customer's inquiry that addresses \"\n",
    "        \"all aspects of their question.\\n\"\n",
    "        \"The response should include references \"\n",
    "        \"to everything you used to find the answer, \"\n",
    "        \"including external data or solutions. \"\n",
    "        \"Ensure the answer is complete, \"\n",
    "\t\t\"leaving no questions unanswered, and maintain a helpful and friendly \"\n",
    "\t\t\"tone throughout.\"\n",
    "    ),\n",
    "\ttools=[docs_scrape_tool],\n",
    "    agent=support_agent,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 438
   },
   "outputs": [],
   "source": [
    "quality_assurance_review = Task(\n",
    "    description=(\n",
    "        \"Review the response drafted by the Senior Support Representative for {customer}'s inquiry. \"\n",
    "        \"Ensure that the answer is comprehensive, accurate, and adheres to the \"\n",
    "\t\t\"high-quality standards expected for customer support.\\n\"\n",
    "        \"Verify that all parts of the customer's inquiry \"\n",
    "        \"have been addressed \"\n",
    "\t\t\"thoroughly, with a helpful and friendly tone.\\n\"\n",
    "        \"Check for references and sources used to \"\n",
    "        \" find the information, \"\n",
    "\t\t\"ensuring the response is well-supported and \"\n",
    "        \"leaves no questions unanswered.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A final, detailed, and informative response \"\n",
    "        \"ready to be sent to the customer.\\n\"\n",
    "        \"This response should fully address the \"\n",
    "        \"customer's inquiry, incorporating all \"\n",
    "\t\t\"relevant feedback and improvements.\\n\"\n",
    "\t\t\"Don't be too formal, we are a chill and cool company \"\n",
    "\t    \"but maintain a professional and friendly tone throughout.\"\n",
    "    ),\n",
    "    agent=support_quality_assurance_agent,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Crew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "crew = Crew(\n",
    "  agents=[support_agent, support_quality_assurance_agent],\n",
    "  tasks=[inquiry_resolution, quality_assurance_review],\n",
    "  verbose=2,\n",
    "  memory=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running the Crew\n",
    "\n",
    "**Note**: LLMs can provide different outputs for the same input. Because we are using a different model, the output you get will likely be different from the original tutorial, but the process the agents follow will be the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = {\n",
    "    \"customer\": \"DeepLearningAI\",\n",
    "    \"person\": \"Andrew Ng\",\n",
    "    \"inquiry\": \"I need help with setting up a Crew \"\n",
    "               \"and kicking it off, specifically \"\n",
    "               \"how can I add memory to my crew? \"\n",
    "               \"Can you provide guidance?\"\n",
    "}\n",
    "result = crew.kickoff(inputs=inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Display the final result as Markdown."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "from IPython.display import Markdown\n",
    "Markdown(result)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}